{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38bf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5f2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4453aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5634a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (0.12.6)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356dce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrochelleli\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96238344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rochelleli/w251-hw9/runs/285ki779\" target=\"_blank\">frightful-horseman-6</a></strong> to <a href=\"https://wandb.ai/rochelleli/w251-hw9\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rochelleli/w251-hw9/runs/285ki779?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f013858bf70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"w251-hw9\", entity=\"rochelleli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b249977",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=2\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16936a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf8e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440d78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 2\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH=500\n",
    "VAL_BATCH=500\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/home/ubuntu/data/train\"\n",
    "VALDIR=\"/home/ubuntu/data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0c0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b173c1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:285ki779) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 603... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">frightful-horseman-6</strong>: <a href=\"https://wandb.ai/rochelleli/w251-hw9/runs/285ki779\" target=\"_blank\">https://wandb.ai/rochelleli/w251-hw9/runs/285ki779</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211031_103311-285ki779/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:285ki779). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rochelleli/w251-hw9-slave/runs/2siffccy\" target=\"_blank\">possessed-crone-1</a></strong> to <a href=\"https://wandb.ai/rochelleli/w251-hw9-slave\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rochelleli/w251-hw9-slave/runs/2siffccy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0224693400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fddca9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc5cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "708e1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb097f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "        \n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6413ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    global_step = global_step + 1\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95fc3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4923dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895100c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f79f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "439e3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f14c4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f0415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "027db00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "\n",
    "URL = 'tcp://172.31.17.123:443'\n",
    "\n",
    "RANK = 1\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method=URL,rank=RANK, world_size=WORLD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "597c9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8beb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3890a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afd4ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c0f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae2abfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd7e287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af72136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b17f3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a3ff83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c397ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomCrop(IMG_SIZE, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fda3813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc075466",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomCrop(IMG_SIZE, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a3e8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21280091",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adfd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc5823ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "759e44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 15.616 (15.616)\tData  4.128 ( 4.128)\tLoss 7.0156e+00 (7.0156e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  10/1282]\tTime  0.785 ( 2.468)\tData  0.127 ( 0.819)\tLoss 6.9182e+00 (6.9759e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   0.80 (  0.64)\n",
      "Epoch: [0][  20/1282]\tTime  0.754 ( 2.112)\tData  0.002 ( 0.916)\tLoss 6.9132e+00 (6.9532e+00)\tAcc@1   0.60 (  0.17)\tAcc@5   1.80 (  0.84)\n",
      "Epoch: [0][  30/1282]\tTime  0.764 ( 1.991)\tData  0.003 ( 0.945)\tLoss 6.8345e+00 (6.9262e+00)\tAcc@1   0.00 (  0.23)\tAcc@5   2.00 (  1.00)\n",
      "Epoch: [0][  40/1282]\tTime  0.758 ( 1.902)\tData  0.002 ( 0.938)\tLoss 6.7156e+00 (6.8819e+00)\tAcc@1   0.60 (  0.38)\tAcc@5   3.20 (  1.40)\n",
      "Epoch: [0][  50/1282]\tTime  0.667 ( 1.863)\tData  0.003 ( 0.948)\tLoss 6.6571e+00 (6.8398e+00)\tAcc@1   0.60 (  0.46)\tAcc@5   2.00 (  1.69)\n",
      "Epoch: [0][  60/1282]\tTime  0.695 ( 1.849)\tData  0.002 ( 0.968)\tLoss 6.5180e+00 (6.7952e+00)\tAcc@1   0.60 (  0.52)\tAcc@5   3.40 (  1.95)\n",
      "Epoch: [0][  70/1282]\tTime  0.755 ( 1.820)\tData  0.089 ( 0.966)\tLoss 6.4503e+00 (6.7562e+00)\tAcc@1   1.40 (  0.57)\tAcc@5   5.20 (  2.18)\n",
      "Epoch: [0][  80/1282]\tTime  0.875 ( 1.809)\tData  0.211 ( 0.976)\tLoss 6.3870e+00 (6.7132e+00)\tAcc@1   1.40 (  0.67)\tAcc@5   4.40 (  2.48)\n",
      "Epoch: [0][  90/1282]\tTime  1.269 ( 1.791)\tData  0.602 ( 0.976)\tLoss 6.3428e+00 (6.6711e+00)\tAcc@1   1.40 (  0.77)\tAcc@5   5.20 (  2.80)\n",
      "Epoch: [0][ 100/1282]\tTime  1.650 ( 1.784)\tData  0.982 ( 0.984)\tLoss 6.1171e+00 (6.6282e+00)\tAcc@1   2.80 (  0.84)\tAcc@5   7.00 (  3.09)\n",
      "Epoch: [0][ 110/1282]\tTime  1.124 ( 1.769)\tData  0.454 ( 0.980)\tLoss 6.0713e+00 (6.5847e+00)\tAcc@1   3.60 (  0.95)\tAcc@5   9.60 (  3.41)\n",
      "Epoch: [0][ 120/1282]\tTime  1.230 ( 1.766)\tData  0.556 ( 0.987)\tLoss 6.0898e+00 (6.5466e+00)\tAcc@1   4.00 (  1.04)\tAcc@5   8.20 (  3.70)\n",
      "Epoch: [0][ 130/1282]\tTime  1.233 ( 1.760)\tData  0.557 ( 0.989)\tLoss 5.9793e+00 (6.5097e+00)\tAcc@1   1.60 (  1.13)\tAcc@5   8.40 (  3.98)\n",
      "Epoch: [0][ 140/1282]\tTime  1.002 ( 1.750)\tData  0.322 ( 0.985)\tLoss 6.0553e+00 (6.4755e+00)\tAcc@1   2.00 (  1.21)\tAcc@5   8.00 (  4.30)\n",
      "Epoch: [0][ 150/1282]\tTime  0.981 ( 1.752)\tData  0.300 ( 0.993)\tLoss 5.9538e+00 (6.4393e+00)\tAcc@1   2.80 (  1.30)\tAcc@5  10.00 (  4.59)\n",
      "Epoch: [0][ 160/1282]\tTime  0.772 ( 1.744)\tData  0.091 ( 0.990)\tLoss 5.8895e+00 (6.4059e+00)\tAcc@1   2.40 (  1.38)\tAcc@5   9.80 (  4.90)\n",
      "Epoch: [0][ 170/1282]\tTime  0.770 ( 1.738)\tData  0.090 ( 0.988)\tLoss 5.7753e+00 (6.3738e+00)\tAcc@1   5.20 (  1.47)\tAcc@5   9.60 (  5.17)\n",
      "Epoch: [0][ 180/1282]\tTime  0.773 ( 1.736)\tData  0.092 ( 0.988)\tLoss 5.8273e+00 (6.3423e+00)\tAcc@1   2.80 (  1.58)\tAcc@5   9.40 (  5.45)\n",
      "Epoch: [0][ 190/1282]\tTime  0.687 ( 1.732)\tData  0.002 ( 0.987)\tLoss 5.7511e+00 (6.3109e+00)\tAcc@1   3.60 (  1.67)\tAcc@5  11.40 (  5.72)\n",
      "Epoch: [0][ 200/1282]\tTime  0.721 ( 1.735)\tData  0.002 ( 0.991)\tLoss 5.7846e+00 (6.2832e+00)\tAcc@1   4.00 (  1.77)\tAcc@5  11.20 (  6.00)\n",
      "Epoch: [0][ 210/1282]\tTime  0.690 ( 1.729)\tData  0.003 ( 0.987)\tLoss 5.6590e+00 (6.2540e+00)\tAcc@1   4.20 (  1.87)\tAcc@5  11.20 (  6.29)\n",
      "Epoch: [0][ 220/1282]\tTime  0.689 ( 1.728)\tData  0.003 ( 0.987)\tLoss 5.6057e+00 (6.2269e+00)\tAcc@1   4.60 (  1.99)\tAcc@5  12.40 (  6.56)\n",
      "Epoch: [0][ 230/1282]\tTime  0.691 ( 1.725)\tData  0.002 ( 0.986)\tLoss 5.5602e+00 (6.2001e+00)\tAcc@1   6.60 (  2.11)\tAcc@5  14.20 (  6.85)\n",
      "Epoch: [0][ 240/1282]\tTime  0.698 ( 1.722)\tData  0.002 ( 0.984)\tLoss 5.5252e+00 (6.1724e+00)\tAcc@1   5.60 (  2.22)\tAcc@5  14.60 (  7.18)\n",
      "Epoch: [0][ 250/1282]\tTime  0.694 ( 1.720)\tData  0.002 ( 0.983)\tLoss 5.5984e+00 (6.1456e+00)\tAcc@1   4.40 (  2.32)\tAcc@5  12.40 (  7.47)\n",
      "Epoch: [0][ 260/1282]\tTime  0.714 ( 1.720)\tData  0.002 ( 0.985)\tLoss 5.5894e+00 (6.1197e+00)\tAcc@1   4.20 (  2.43)\tAcc@5  14.60 (  7.78)\n",
      "Epoch: [0][ 270/1282]\tTime  0.724 ( 1.717)\tData  0.002 ( 0.983)\tLoss 5.3588e+00 (6.0944e+00)\tAcc@1   5.40 (  2.54)\tAcc@5  16.60 (  8.09)\n",
      "Epoch: [0][ 280/1282]\tTime  0.714 ( 1.716)\tData  0.002 ( 0.983)\tLoss 5.3976e+00 (6.0702e+00)\tAcc@1   7.00 (  2.66)\tAcc@5  17.40 (  8.37)\n",
      "Epoch: [0][ 290/1282]\tTime  0.712 ( 1.718)\tData  0.003 ( 0.985)\tLoss 5.3315e+00 (6.0474e+00)\tAcc@1   7.40 (  2.77)\tAcc@5  18.00 (  8.64)\n",
      "Epoch: [0][ 300/1282]\tTime  0.722 ( 1.714)\tData  0.003 ( 0.983)\tLoss 5.2160e+00 (6.0225e+00)\tAcc@1   8.80 (  2.91)\tAcc@5  20.60 (  8.99)\n",
      "Epoch: [0][ 310/1282]\tTime  0.734 ( 1.716)\tData  0.002 ( 0.985)\tLoss 5.2408e+00 (5.9975e+00)\tAcc@1   5.60 (  3.03)\tAcc@5  17.60 (  9.30)\n",
      "Epoch: [0][ 320/1282]\tTime  0.718 ( 1.714)\tData  0.003 ( 0.985)\tLoss 5.2504e+00 (5.9747e+00)\tAcc@1   7.00 (  3.13)\tAcc@5  19.60 (  9.57)\n",
      "Epoch: [0][ 330/1282]\tTime  0.714 ( 1.713)\tData  0.003 ( 0.984)\tLoss 5.2507e+00 (5.9515e+00)\tAcc@1   6.80 (  3.25)\tAcc@5  19.40 (  9.88)\n",
      "Epoch: [0][ 340/1282]\tTime  0.683 ( 1.714)\tData  0.003 ( 0.986)\tLoss 5.0554e+00 (5.9281e+00)\tAcc@1   6.80 (  3.37)\tAcc@5  18.40 ( 10.16)\n",
      "Epoch: [0][ 350/1282]\tTime  0.682 ( 1.712)\tData  0.002 ( 0.984)\tLoss 5.3180e+00 (5.9071e+00)\tAcc@1   8.20 (  3.48)\tAcc@5  19.60 ( 10.43)\n",
      "Epoch: [0][ 360/1282]\tTime  0.727 ( 1.713)\tData  0.002 ( 0.986)\tLoss 5.1153e+00 (5.8847e+00)\tAcc@1   6.60 (  3.60)\tAcc@5  20.40 ( 10.73)\n",
      "Epoch: [0][ 370/1282]\tTime  0.694 ( 1.711)\tData  0.003 ( 0.985)\tLoss 5.1310e+00 (5.8657e+00)\tAcc@1   9.40 (  3.69)\tAcc@5  22.00 ( 10.97)\n",
      "Epoch: [0][ 380/1282]\tTime  0.693 ( 1.711)\tData  0.002 ( 0.986)\tLoss 4.9869e+00 (5.8452e+00)\tAcc@1   8.20 (  3.81)\tAcc@5  23.80 ( 11.26)\n",
      "Epoch: [0][ 390/1282]\tTime  0.708 ( 1.711)\tData  0.002 ( 0.987)\tLoss 5.0462e+00 (5.8253e+00)\tAcc@1   7.80 (  3.93)\tAcc@5  21.20 ( 11.55)\n",
      "Epoch: [0][ 400/1282]\tTime  0.713 ( 1.708)\tData  0.002 ( 0.984)\tLoss 5.0080e+00 (5.8062e+00)\tAcc@1   9.20 (  4.05)\tAcc@5  22.40 ( 11.79)\n",
      "Epoch: [0][ 410/1282]\tTime  0.785 ( 1.706)\tData  0.002 ( 0.983)\tLoss 4.9063e+00 (5.7881e+00)\tAcc@1   9.40 (  4.16)\tAcc@5  26.60 ( 12.07)\n",
      "Epoch: [0][ 420/1282]\tTime  0.724 ( 1.708)\tData  0.002 ( 0.984)\tLoss 4.9459e+00 (5.7690e+00)\tAcc@1   9.40 (  4.28)\tAcc@5  24.20 ( 12.35)\n",
      "Epoch: [0][ 430/1282]\tTime  0.717 ( 1.706)\tData  0.003 ( 0.983)\tLoss 4.9767e+00 (5.7492e+00)\tAcc@1   7.00 (  4.39)\tAcc@5  23.60 ( 12.65)\n",
      "Epoch: [0][ 440/1282]\tTime  0.688 ( 1.706)\tData  0.003 ( 0.984)\tLoss 5.0452e+00 (5.7317e+00)\tAcc@1   7.60 (  4.50)\tAcc@5  20.80 ( 12.91)\n",
      "Epoch: [0][ 450/1282]\tTime  0.686 ( 1.705)\tData  0.002 ( 0.983)\tLoss 4.6303e+00 (5.7134e+00)\tAcc@1  11.00 (  4.62)\tAcc@5  26.40 ( 13.17)\n",
      "Epoch: [0][ 460/1282]\tTime  0.684 ( 1.706)\tData  0.002 ( 0.985)\tLoss 4.9812e+00 (5.6956e+00)\tAcc@1   9.40 (  4.73)\tAcc@5  23.60 ( 13.43)\n",
      "Epoch: [0][ 470/1282]\tTime  0.690 ( 1.705)\tData  0.002 ( 0.985)\tLoss 4.8761e+00 (5.6773e+00)\tAcc@1  10.60 (  4.83)\tAcc@5  23.80 ( 13.68)\n",
      "Epoch: [0][ 480/1282]\tTime  0.716 ( 1.708)\tData  0.002 ( 0.988)\tLoss 4.7287e+00 (5.6586e+00)\tAcc@1  13.40 (  4.96)\tAcc@5  29.60 ( 13.95)\n",
      "Epoch: [0][ 490/1282]\tTime  0.689 ( 1.706)\tData  0.003 ( 0.987)\tLoss 4.6827e+00 (5.6409e+00)\tAcc@1   9.80 (  5.07)\tAcc@5  28.60 ( 14.21)\n",
      "Epoch: [0][ 500/1282]\tTime  0.683 ( 1.705)\tData  0.002 ( 0.986)\tLoss 4.8340e+00 (5.6235e+00)\tAcc@1  12.60 (  5.19)\tAcc@5  27.00 ( 14.47)\n",
      "Epoch: [0][ 510/1282]\tTime  0.726 ( 1.705)\tData  0.003 ( 0.986)\tLoss 4.8993e+00 (5.6076e+00)\tAcc@1  10.00 (  5.29)\tAcc@5  23.80 ( 14.72)\n",
      "Epoch: [0][ 520/1282]\tTime  0.685 ( 1.704)\tData  0.002 ( 0.986)\tLoss 4.7570e+00 (5.5909e+00)\tAcc@1   8.60 (  5.40)\tAcc@5  25.40 ( 14.97)\n",
      "Epoch: [0][ 530/1282]\tTime  0.691 ( 1.706)\tData  0.002 ( 0.988)\tLoss 4.6879e+00 (5.5737e+00)\tAcc@1  11.40 (  5.51)\tAcc@5  28.80 ( 15.23)\n",
      "Epoch: [0][ 540/1282]\tTime  0.683 ( 1.706)\tData  0.002 ( 0.988)\tLoss 4.6027e+00 (5.5574e+00)\tAcc@1  13.60 (  5.64)\tAcc@5  30.40 ( 15.47)\n",
      "Epoch: [0][ 550/1282]\tTime  0.691 ( 1.705)\tData  0.003 ( 0.988)\tLoss 4.5799e+00 (5.5414e+00)\tAcc@1  12.80 (  5.75)\tAcc@5  31.00 ( 15.72)\n",
      "Epoch: [0][ 560/1282]\tTime  0.684 ( 1.705)\tData  0.002 ( 0.988)\tLoss 4.5369e+00 (5.5250e+00)\tAcc@1  14.80 (  5.86)\tAcc@5  31.00 ( 15.98)\n",
      "Epoch: [0][ 570/1282]\tTime  0.716 ( 1.704)\tData  0.002 ( 0.987)\tLoss 4.6132e+00 (5.5088e+00)\tAcc@1  11.20 (  5.98)\tAcc@5  30.80 ( 16.22)\n",
      "Epoch: [0][ 580/1282]\tTime  0.723 ( 1.706)\tData  0.002 ( 0.989)\tLoss 4.6203e+00 (5.4932e+00)\tAcc@1  14.40 (  6.09)\tAcc@5  30.40 ( 16.46)\n",
      "Epoch: [0][ 590/1282]\tTime  0.687 ( 1.704)\tData  0.002 ( 0.988)\tLoss 4.8022e+00 (5.4782e+00)\tAcc@1  13.00 (  6.21)\tAcc@5  26.00 ( 16.68)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 600/1282]\tTime  0.680 ( 1.704)\tData  0.002 ( 0.988)\tLoss 4.7113e+00 (5.4627e+00)\tAcc@1  12.40 (  6.34)\tAcc@5  28.60 ( 16.92)\n",
      "Epoch: [0][ 610/1282]\tTime  0.679 ( 1.703)\tData  0.002 ( 0.988)\tLoss 4.6303e+00 (5.4466e+00)\tAcc@1  15.00 (  6.47)\tAcc@5  29.60 ( 17.18)\n",
      "Epoch: [0][ 620/1282]\tTime  0.781 ( 1.703)\tData  0.002 ( 0.987)\tLoss 4.4353e+00 (5.4315e+00)\tAcc@1  11.40 (  6.57)\tAcc@5  35.20 ( 17.41)\n",
      "Epoch: [0][ 630/1282]\tTime  0.680 ( 1.703)\tData  0.002 ( 0.987)\tLoss 4.3729e+00 (5.4163e+00)\tAcc@1  16.00 (  6.70)\tAcc@5  36.20 ( 17.67)\n",
      "Epoch: [0][ 640/1282]\tTime  0.687 ( 1.702)\tData  0.002 ( 0.986)\tLoss 4.5844e+00 (5.4018e+00)\tAcc@1  13.20 (  6.80)\tAcc@5  32.00 ( 17.89)\n",
      "Epoch: [0][ 650/1282]\tTime  0.682 ( 1.702)\tData  0.002 ( 0.987)\tLoss 4.3705e+00 (5.3878e+00)\tAcc@1  16.60 (  6.91)\tAcc@5  35.20 ( 18.14)\n",
      "Epoch: [0][ 660/1282]\tTime  0.685 ( 1.701)\tData  0.002 ( 0.986)\tLoss 4.4043e+00 (5.3734e+00)\tAcc@1  14.20 (  7.03)\tAcc@5  33.60 ( 18.37)\n",
      "Epoch: [0][ 670/1282]\tTime  0.781 ( 1.701)\tData  0.002 ( 0.986)\tLoss 4.3554e+00 (5.3589e+00)\tAcc@1  14.00 (  7.13)\tAcc@5  33.80 ( 18.60)\n",
      "Epoch: [0][ 680/1282]\tTime  0.685 ( 1.701)\tData  0.002 ( 0.986)\tLoss 4.3822e+00 (5.3447e+00)\tAcc@1  14.60 (  7.24)\tAcc@5  34.00 ( 18.84)\n",
      "Epoch: [0][ 690/1282]\tTime  0.784 ( 1.701)\tData  0.002 ( 0.986)\tLoss 4.3757e+00 (5.3306e+00)\tAcc@1  16.20 (  7.35)\tAcc@5  32.00 ( 19.06)\n",
      "Epoch: [0][ 700/1282]\tTime  0.683 ( 1.701)\tData  0.002 ( 0.986)\tLoss 4.4211e+00 (5.3172e+00)\tAcc@1  13.00 (  7.46)\tAcc@5  31.80 ( 19.27)\n",
      "Epoch: [0][ 710/1282]\tTime  0.686 ( 1.700)\tData  0.002 ( 0.985)\tLoss 4.5209e+00 (5.3030e+00)\tAcc@1  12.00 (  7.57)\tAcc@5  28.60 ( 19.51)\n",
      "Epoch: [0][ 720/1282]\tTime  0.782 ( 1.701)\tData  0.002 ( 0.986)\tLoss 4.2508e+00 (5.2898e+00)\tAcc@1  16.40 (  7.67)\tAcc@5  37.00 ( 19.72)\n",
      "Epoch: [0][ 730/1282]\tTime  0.685 ( 1.700)\tData  0.002 ( 0.985)\tLoss 4.3283e+00 (5.2759e+00)\tAcc@1  15.40 (  7.78)\tAcc@5  34.80 ( 19.96)\n",
      "Epoch: [0][ 740/1282]\tTime  0.776 ( 1.700)\tData  0.002 ( 0.985)\tLoss 4.3973e+00 (5.2624e+00)\tAcc@1  14.80 (  7.89)\tAcc@5  33.60 ( 20.19)\n",
      "Epoch: [0][ 750/1282]\tTime  0.786 ( 1.699)\tData  0.002 ( 0.984)\tLoss 4.3244e+00 (5.2493e+00)\tAcc@1  14.80 (  8.01)\tAcc@5  34.00 ( 20.41)\n",
      "Epoch: [0][ 760/1282]\tTime  0.885 ( 1.699)\tData  0.002 ( 0.983)\tLoss 4.3745e+00 (5.2360e+00)\tAcc@1  14.80 (  8.14)\tAcc@5  34.60 ( 20.63)\n",
      "Epoch: [0][ 770/1282]\tTime  0.883 ( 1.699)\tData  0.003 ( 0.983)\tLoss 4.0093e+00 (5.2225e+00)\tAcc@1  19.20 (  8.25)\tAcc@5  42.00 ( 20.86)\n",
      "Epoch: [0][ 780/1282]\tTime  0.792 ( 1.699)\tData  0.003 ( 0.982)\tLoss 4.1069e+00 (5.2092e+00)\tAcc@1  18.80 (  8.36)\tAcc@5  42.20 ( 21.09)\n",
      "Epoch: [0][ 790/1282]\tTime  0.789 ( 1.698)\tData  0.002 ( 0.981)\tLoss 4.1137e+00 (5.1965e+00)\tAcc@1  17.00 (  8.47)\tAcc@5  39.20 ( 21.30)\n",
      "Epoch: [0][ 800/1282]\tTime  0.886 ( 1.699)\tData  0.003 ( 0.982)\tLoss 4.1481e+00 (5.1840e+00)\tAcc@1  16.40 (  8.57)\tAcc@5  37.80 ( 21.50)\n",
      "Epoch: [0][ 810/1282]\tTime  0.883 ( 1.698)\tData  0.002 ( 0.980)\tLoss 4.1009e+00 (5.1711e+00)\tAcc@1  18.60 (  8.69)\tAcc@5  39.60 ( 21.73)\n",
      "Epoch: [0][ 820/1282]\tTime  0.886 ( 1.698)\tData  0.002 ( 0.979)\tLoss 4.1877e+00 (5.1582e+00)\tAcc@1  16.00 (  8.81)\tAcc@5  39.40 ( 21.95)\n",
      "Epoch: [0][ 830/1282]\tTime  0.782 ( 1.697)\tData  0.002 ( 0.978)\tLoss 4.1428e+00 (5.1458e+00)\tAcc@1  18.20 (  8.92)\tAcc@5  40.00 ( 22.17)\n",
      "Epoch: [0][ 840/1282]\tTime  1.090 ( 1.696)\tData  0.002 ( 0.976)\tLoss 4.1567e+00 (5.1338e+00)\tAcc@1  18.40 (  9.03)\tAcc@5  37.40 ( 22.37)\n",
      "Epoch: [0][ 850/1282]\tTime  0.886 ( 1.697)\tData  0.002 ( 0.976)\tLoss 3.9054e+00 (5.1213e+00)\tAcc@1  21.20 (  9.15)\tAcc@5  41.20 ( 22.58)\n",
      "Epoch: [0][ 860/1282]\tTime  0.889 ( 1.697)\tData  0.002 ( 0.975)\tLoss 4.1883e+00 (5.1095e+00)\tAcc@1  17.40 (  9.27)\tAcc@5  37.80 ( 22.79)\n",
      "Epoch: [0][ 870/1282]\tTime  0.685 ( 1.697)\tData  0.002 ( 0.975)\tLoss 3.9826e+00 (5.0973e+00)\tAcc@1  18.20 (  9.37)\tAcc@5  42.80 ( 23.00)\n",
      "Epoch: [0][ 880/1282]\tTime  0.784 ( 1.697)\tData  0.002 ( 0.975)\tLoss 4.0327e+00 (5.0857e+00)\tAcc@1  19.40 (  9.48)\tAcc@5  39.40 ( 23.18)\n",
      "Epoch: [0][ 890/1282]\tTime  0.791 ( 1.697)\tData  0.003 ( 0.975)\tLoss 4.0477e+00 (5.0735e+00)\tAcc@1  20.40 (  9.59)\tAcc@5  40.40 ( 23.39)\n",
      "Epoch: [0][ 900/1282]\tTime  0.897 ( 1.697)\tData  0.002 ( 0.974)\tLoss 4.0316e+00 (5.0619e+00)\tAcc@1  20.00 (  9.70)\tAcc@5  43.60 ( 23.59)\n",
      "Epoch: [0][ 910/1282]\tTime  0.683 ( 1.697)\tData  0.003 ( 0.975)\tLoss 3.9351e+00 (5.0503e+00)\tAcc@1  18.80 (  9.81)\tAcc@5  45.40 ( 23.79)\n",
      "Epoch: [0][ 920/1282]\tTime  0.684 ( 1.696)\tData  0.002 ( 0.974)\tLoss 3.8933e+00 (5.0382e+00)\tAcc@1  20.80 (  9.92)\tAcc@5  42.80 ( 24.00)\n",
      "Epoch: [0][ 930/1282]\tTime  0.682 ( 1.696)\tData  0.002 ( 0.974)\tLoss 3.9266e+00 (5.0268e+00)\tAcc@1  20.80 ( 10.03)\tAcc@5  42.80 ( 24.20)\n",
      "Epoch: [0][ 940/1282]\tTime  0.781 ( 1.696)\tData  0.002 ( 0.974)\tLoss 4.0094e+00 (5.0156e+00)\tAcc@1  20.20 ( 10.14)\tAcc@5  44.60 ( 24.39)\n",
      "Epoch: [0][ 950/1282]\tTime  0.783 ( 1.696)\tData  0.002 ( 0.974)\tLoss 4.0414e+00 (5.0043e+00)\tAcc@1  18.20 ( 10.25)\tAcc@5  39.80 ( 24.59)\n",
      "Epoch: [0][ 960/1282]\tTime  0.685 ( 1.695)\tData  0.002 ( 0.973)\tLoss 3.8781e+00 (4.9928e+00)\tAcc@1  22.80 ( 10.36)\tAcc@5  41.20 ( 24.79)\n",
      "Epoch: [0][ 970/1282]\tTime  0.778 ( 1.695)\tData  0.002 ( 0.973)\tLoss 3.9890e+00 (4.9815e+00)\tAcc@1  17.60 ( 10.47)\tAcc@5  39.40 ( 24.98)\n",
      "Epoch: [0][ 980/1282]\tTime  0.777 ( 1.695)\tData  0.002 ( 0.973)\tLoss 3.7915e+00 (4.9706e+00)\tAcc@1  27.00 ( 10.58)\tAcc@5  47.00 ( 25.17)\n",
      "Epoch: [0][ 990/1282]\tTime  0.793 ( 1.695)\tData  0.002 ( 0.972)\tLoss 3.8234e+00 (4.9597e+00)\tAcc@1  19.20 ( 10.69)\tAcc@5  41.80 ( 25.36)\n",
      "Epoch: [0][1000/1282]\tTime  0.713 ( 1.695)\tData  0.002 ( 0.973)\tLoss 3.9626e+00 (4.9495e+00)\tAcc@1  19.20 ( 10.78)\tAcc@5  43.60 ( 25.54)\n",
      "Epoch: [0][1010/1282]\tTime  0.779 ( 1.695)\tData  0.002 ( 0.973)\tLoss 3.8322e+00 (4.9389e+00)\tAcc@1  22.60 ( 10.88)\tAcc@5  46.40 ( 25.73)\n",
      "Epoch: [0][1020/1282]\tTime  0.881 ( 1.694)\tData  0.002 ( 0.972)\tLoss 3.8501e+00 (4.9287e+00)\tAcc@1  22.20 ( 10.98)\tAcc@5  46.80 ( 25.91)\n",
      "Epoch: [0][1030/1282]\tTime  0.680 ( 1.694)\tData  0.003 ( 0.972)\tLoss 3.8828e+00 (4.9180e+00)\tAcc@1  22.00 ( 11.09)\tAcc@5  45.20 ( 26.10)\n",
      "Epoch: [0][1040/1282]\tTime  0.880 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.7546e+00 (4.9072e+00)\tAcc@1  21.00 ( 11.20)\tAcc@5  46.60 ( 26.29)\n",
      "Epoch: [0][1050/1282]\tTime  0.781 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.6075e+00 (4.8963e+00)\tAcc@1  26.20 ( 11.32)\tAcc@5  52.20 ( 26.48)\n",
      "Epoch: [0][1060/1282]\tTime  0.682 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.7612e+00 (4.8858e+00)\tAcc@1  21.80 ( 11.42)\tAcc@5  44.60 ( 26.67)\n",
      "Epoch: [0][1070/1282]\tTime  0.698 ( 1.695)\tData  0.002 ( 0.972)\tLoss 3.7519e+00 (4.8759e+00)\tAcc@1  21.60 ( 11.51)\tAcc@5  45.40 ( 26.84)\n",
      "Epoch: [0][1080/1282]\tTime  0.685 ( 1.695)\tData  0.002 ( 0.972)\tLoss 3.6946e+00 (4.8655e+00)\tAcc@1  24.80 ( 11.62)\tAcc@5  50.80 ( 27.04)\n",
      "Epoch: [0][1090/1282]\tTime  0.719 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.7519e+00 (4.8554e+00)\tAcc@1  22.80 ( 11.72)\tAcc@5  45.20 ( 27.21)\n",
      "Epoch: [0][1100/1282]\tTime  0.717 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.8187e+00 (4.8448e+00)\tAcc@1  23.60 ( 11.83)\tAcc@5  46.00 ( 27.40)\n",
      "Epoch: [0][1110/1282]\tTime  0.714 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.6997e+00 (4.8355e+00)\tAcc@1  23.40 ( 11.93)\tAcc@5  47.40 ( 27.56)\n",
      "Epoch: [0][1120/1282]\tTime  0.696 ( 1.694)\tData  0.002 ( 0.971)\tLoss 3.7813e+00 (4.8253e+00)\tAcc@1  21.40 ( 12.04)\tAcc@5  43.40 ( 27.74)\n",
      "Epoch: [0][1130/1282]\tTime  0.779 ( 1.693)\tData  0.002 ( 0.971)\tLoss 3.7684e+00 (4.8158e+00)\tAcc@1  24.60 ( 12.14)\tAcc@5  45.00 ( 27.92)\n",
      "Epoch: [0][1140/1282]\tTime  0.794 ( 1.693)\tData  0.003 ( 0.970)\tLoss 3.4775e+00 (4.8056e+00)\tAcc@1  28.00 ( 12.25)\tAcc@5  54.00 ( 28.10)\n",
      "Epoch: [0][1150/1282]\tTime  0.785 ( 1.692)\tData  0.002 ( 0.969)\tLoss 3.7545e+00 (4.7956e+00)\tAcc@1  23.80 ( 12.35)\tAcc@5  46.20 ( 28.28)\n",
      "Epoch: [0][1160/1282]\tTime  0.782 ( 1.692)\tData  0.003 ( 0.969)\tLoss 3.8042e+00 (4.7861e+00)\tAcc@1  21.80 ( 12.44)\tAcc@5  45.40 ( 28.44)\n",
      "Epoch: [0][1170/1282]\tTime  0.780 ( 1.692)\tData  0.002 ( 0.969)\tLoss 3.8155e+00 (4.7769e+00)\tAcc@1  22.20 ( 12.54)\tAcc@5  46.40 ( 28.60)\n",
      "Epoch: [0][1180/1282]\tTime  0.680 ( 1.692)\tData  0.002 ( 0.969)\tLoss 3.7569e+00 (4.7673e+00)\tAcc@1  24.20 ( 12.65)\tAcc@5  46.20 ( 28.77)\n",
      "Epoch: [0][1190/1282]\tTime  0.692 ( 1.691)\tData  0.003 ( 0.969)\tLoss 3.7393e+00 (4.7578e+00)\tAcc@1  23.60 ( 12.75)\tAcc@5  50.60 ( 28.94)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1200/1282]\tTime  0.778 ( 1.690)\tData  0.002 ( 0.968)\tLoss 3.5538e+00 (4.7478e+00)\tAcc@1  25.60 ( 12.86)\tAcc@5  50.20 ( 29.13)\n",
      "Epoch: [0][1210/1282]\tTime  0.689 ( 1.691)\tData  0.002 ( 0.968)\tLoss 3.7215e+00 (4.7378e+00)\tAcc@1  21.00 ( 12.97)\tAcc@5  48.00 ( 29.31)\n",
      "Epoch: [0][1220/1282]\tTime  0.688 ( 1.690)\tData  0.002 ( 0.968)\tLoss 3.6594e+00 (4.7287e+00)\tAcc@1  24.40 ( 13.06)\tAcc@5  47.40 ( 29.48)\n",
      "Epoch: [0][1230/1282]\tTime  0.715 ( 1.690)\tData  0.002 ( 0.968)\tLoss 3.6392e+00 (4.7193e+00)\tAcc@1  24.40 ( 13.16)\tAcc@5  47.60 ( 29.64)\n",
      "Epoch: [0][1240/1282]\tTime  0.713 ( 1.691)\tData  0.002 ( 0.969)\tLoss 3.5611e+00 (4.7102e+00)\tAcc@1  25.60 ( 13.25)\tAcc@5  51.40 ( 29.80)\n",
      "Epoch: [0][1250/1282]\tTime  0.723 ( 1.690)\tData  0.002 ( 0.969)\tLoss 3.4320e+00 (4.7010e+00)\tAcc@1  28.20 ( 13.35)\tAcc@5  51.80 ( 29.96)\n",
      "Epoch: [0][1260/1282]\tTime  0.721 ( 1.691)\tData  0.003 ( 0.969)\tLoss 3.6723e+00 (4.6922e+00)\tAcc@1  24.20 ( 13.45)\tAcc@5  47.20 ( 30.11)\n",
      "Epoch: [0][1270/1282]\tTime  0.784 ( 1.690)\tData  0.003 ( 0.969)\tLoss 3.5192e+00 (4.6832e+00)\tAcc@1  25.80 ( 13.55)\tAcc@5  49.80 ( 30.27)\n",
      "Epoch: [0][1280/1282]\tTime  0.782 ( 1.690)\tData  0.002 ( 0.968)\tLoss 3.3037e+00 (4.6737e+00)\tAcc@1  30.20 ( 13.67)\tAcc@5  54.40 ( 30.44)\n",
      "Test: [  0/100]\tTime  7.625 ( 7.625)\tLoss 3.4868e+00 (3.4868e+00)\tAcc@1  24.00 ( 24.00)\tAcc@5  55.00 ( 55.00)\n",
      "Test: [ 10/100]\tTime  2.983 ( 2.085)\tLoss 4.0612e+00 (4.2153e+00)\tAcc@1  25.00 ( 20.56)\tAcc@5  43.60 ( 42.16)\n",
      "Test: [ 20/100]\tTime  2.837 ( 1.902)\tLoss 4.0666e+00 (4.0327e+00)\tAcc@1  10.80 ( 20.34)\tAcc@5  39.40 ( 43.55)\n",
      "Test: [ 30/100]\tTime  2.861 ( 1.831)\tLoss 4.2806e+00 (4.0831e+00)\tAcc@1  19.60 ( 19.03)\tAcc@5  43.00 ( 42.27)\n",
      "Test: [ 40/100]\tTime  2.579 ( 1.799)\tLoss 3.5928e+00 (4.1483e+00)\tAcc@1  25.20 ( 19.02)\tAcc@5  51.00 ( 41.46)\n",
      "Test: [ 50/100]\tTime  2.898 ( 1.779)\tLoss 5.1258e+00 (4.1888e+00)\tAcc@1   9.00 ( 18.22)\tAcc@5  23.00 ( 40.33)\n",
      "Test: [ 60/100]\tTime  2.763 ( 1.767)\tLoss 3.9949e+00 (4.1866e+00)\tAcc@1  24.20 ( 18.38)\tAcc@5  41.00 ( 40.12)\n",
      "Test: [ 70/100]\tTime  2.787 ( 1.750)\tLoss 4.2954e+00 (4.2106e+00)\tAcc@1  14.00 ( 18.12)\tAcc@5  36.40 ( 39.71)\n",
      "Test: [ 80/100]\tTime  2.922 ( 1.739)\tLoss 3.9602e+00 (4.2270e+00)\tAcc@1  22.60 ( 18.09)\tAcc@5  42.60 ( 39.27)\n",
      "Test: [ 90/100]\tTime  2.914 ( 1.729)\tLoss 4.4120e+00 (4.2401e+00)\tAcc@1  17.00 ( 17.88)\tAcc@5  33.20 ( 38.81)\n",
      " * Acc@1 18.516 Acc@5 39.680\n",
      "lr: 0.05\n",
      "Epoch: [1][   0/1282]\tTime  6.129 ( 6.129)\tData  3.830 ( 3.830)\tLoss 3.5821e+00 (3.5821e+00)\tAcc@1  24.00 ( 24.00)\tAcc@5  51.20 ( 51.20)\n",
      "Epoch: [1][  10/1282]\tTime  2.661 ( 2.074)\tData  0.003 ( 0.445)\tLoss 3.5047e+00 (3.4929e+00)\tAcc@1  26.20 ( 25.85)\tAcc@5  52.60 ( 52.00)\n",
      "Epoch: [1][  20/1282]\tTime  2.507 ( 1.861)\tData  0.002 ( 0.238)\tLoss 3.3250e+00 (3.4390e+00)\tAcc@1  27.00 ( 27.16)\tAcc@5  55.00 ( 52.63)\n",
      "Epoch: [1][  30/1282]\tTime  2.762 ( 1.803)\tData  0.002 ( 0.162)\tLoss 3.3054e+00 (3.4048e+00)\tAcc@1  32.60 ( 28.21)\tAcc@5  56.20 ( 53.63)\n",
      "Epoch: [1][  40/1282]\tTime  2.651 ( 1.774)\tData  0.002 ( 0.123)\tLoss 3.3309e+00 (3.3898e+00)\tAcc@1  29.00 ( 28.62)\tAcc@5  55.40 ( 54.03)\n",
      "Epoch: [1][  50/1282]\tTime  2.240 ( 1.743)\tData  0.002 ( 0.100)\tLoss 3.4286e+00 (3.3757e+00)\tAcc@1  26.60 ( 28.89)\tAcc@5  53.00 ( 54.12)\n",
      "Epoch: [1][  60/1282]\tTime  1.499 ( 1.724)\tData  0.002 ( 0.084)\tLoss 3.3240e+00 (3.3696e+00)\tAcc@1  30.40 ( 29.13)\tAcc@5  55.80 ( 54.23)\n",
      "Epoch: [1][  70/1282]\tTime  1.500 ( 1.713)\tData  0.002 ( 0.072)\tLoss 3.2612e+00 (3.3575e+00)\tAcc@1  28.60 ( 29.33)\tAcc@5  54.80 ( 54.47)\n",
      "Epoch: [1][  80/1282]\tTime  0.778 ( 1.699)\tData  0.003 ( 0.064)\tLoss 3.3153e+00 (3.3532e+00)\tAcc@1  32.20 ( 29.43)\tAcc@5  59.00 ( 54.62)\n",
      "Epoch: [1][  90/1282]\tTime  0.780 ( 1.696)\tData  0.002 ( 0.057)\tLoss 3.2589e+00 (3.3479e+00)\tAcc@1  27.60 ( 29.39)\tAcc@5  55.80 ( 54.62)\n",
      "Epoch: [1][ 100/1282]\tTime  0.783 ( 1.693)\tData  0.002 ( 0.051)\tLoss 3.0238e+00 (3.3319e+00)\tAcc@1  35.80 ( 29.67)\tAcc@5  61.00 ( 54.83)\n",
      "Epoch: [1][ 110/1282]\tTime  0.683 ( 1.690)\tData  0.002 ( 0.047)\tLoss 3.1109e+00 (3.3257e+00)\tAcc@1  32.60 ( 29.78)\tAcc@5  60.20 ( 54.99)\n",
      "Epoch: [1][ 120/1282]\tTime  0.683 ( 1.684)\tData  0.002 ( 0.043)\tLoss 3.1702e+00 (3.3187e+00)\tAcc@1  31.80 ( 29.88)\tAcc@5  58.00 ( 55.14)\n",
      "Epoch: [1][ 130/1282]\tTime  0.832 ( 1.682)\tData  0.092 ( 0.042)\tLoss 3.1053e+00 (3.3166e+00)\tAcc@1  31.80 ( 29.85)\tAcc@5  57.60 ( 55.18)\n",
      "Epoch: [1][ 140/1282]\tTime  0.779 ( 1.682)\tData  0.002 ( 0.040)\tLoss 3.3112e+00 (3.3140e+00)\tAcc@1  30.60 ( 29.92)\tAcc@5  55.40 ( 55.23)\n",
      "Epoch: [1][ 150/1282]\tTime  0.682 ( 1.682)\tData  0.002 ( 0.038)\tLoss 3.3099e+00 (3.3053e+00)\tAcc@1  28.80 ( 30.05)\tAcc@5  57.00 ( 55.38)\n",
      "Epoch: [1][ 160/1282]\tTime  0.684 ( 1.683)\tData  0.002 ( 0.035)\tLoss 3.2475e+00 (3.3004e+00)\tAcc@1  29.60 ( 30.16)\tAcc@5  56.40 ( 55.50)\n",
      "Epoch: [1][ 170/1282]\tTime  0.677 ( 1.682)\tData  0.002 ( 0.034)\tLoss 3.0949e+00 (3.2957e+00)\tAcc@1  32.20 ( 30.20)\tAcc@5  58.80 ( 55.56)\n",
      "Epoch: [1][ 180/1282]\tTime  0.681 ( 1.680)\tData  0.002 ( 0.032)\tLoss 3.2992e+00 (3.2921e+00)\tAcc@1  28.20 ( 30.25)\tAcc@5  56.80 ( 55.63)\n",
      "Epoch: [1][ 190/1282]\tTime  0.908 ( 1.678)\tData  0.002 ( 0.033)\tLoss 3.2490e+00 (3.2873e+00)\tAcc@1  30.40 ( 30.32)\tAcc@5  55.40 ( 55.73)\n",
      "Epoch: [1][ 200/1282]\tTime  1.180 ( 1.677)\tData  0.002 ( 0.038)\tLoss 3.3293e+00 (3.2858e+00)\tAcc@1  30.40 ( 30.32)\tAcc@5  55.00 ( 55.79)\n",
      "Epoch: [1][ 210/1282]\tTime  1.283 ( 1.676)\tData  0.002 ( 0.044)\tLoss 3.0960e+00 (3.2810e+00)\tAcc@1  31.80 ( 30.46)\tAcc@5  60.60 ( 55.89)\n",
      "Epoch: [1][ 220/1282]\tTime  1.654 ( 1.675)\tData  0.003 ( 0.048)\tLoss 3.1168e+00 (3.2800e+00)\tAcc@1  34.40 ( 30.50)\tAcc@5  58.40 ( 55.92)\n",
      "Epoch: [1][ 230/1282]\tTime  1.629 ( 1.675)\tData  0.002 ( 0.049)\tLoss 3.1257e+00 (3.2773e+00)\tAcc@1  33.60 ( 30.54)\tAcc@5  58.20 ( 55.97)\n",
      "Epoch: [1][ 240/1282]\tTime  2.015 ( 1.676)\tData  0.002 ( 0.048)\tLoss 3.1253e+00 (3.2724e+00)\tAcc@1  32.20 ( 30.58)\tAcc@5  57.60 ( 56.05)\n",
      "Epoch: [1][ 250/1282]\tTime  2.286 ( 1.677)\tData  0.003 ( 0.046)\tLoss 3.2923e+00 (3.2685e+00)\tAcc@1  30.40 ( 30.67)\tAcc@5  54.00 ( 56.12)\n",
      "Epoch: [1][ 260/1282]\tTime  1.960 ( 1.677)\tData  0.002 ( 0.045)\tLoss 3.4016e+00 (3.2640e+00)\tAcc@1  27.80 ( 30.74)\tAcc@5  53.80 ( 56.20)\n",
      "Epoch: [1][ 270/1282]\tTime  1.807 ( 1.676)\tData  0.002 ( 0.046)\tLoss 3.2121e+00 (3.2614e+00)\tAcc@1  29.80 ( 30.77)\tAcc@5  54.80 ( 56.24)\n",
      "Epoch: [1][ 280/1282]\tTime  1.858 ( 1.675)\tData  0.003 ( 0.048)\tLoss 3.1782e+00 (3.2569e+00)\tAcc@1  33.20 ( 30.84)\tAcc@5  58.60 ( 56.33)\n",
      "Epoch: [1][ 290/1282]\tTime  2.455 ( 1.676)\tData  0.002 ( 0.052)\tLoss 3.0991e+00 (3.2529e+00)\tAcc@1  33.40 ( 30.89)\tAcc@5  58.20 ( 56.38)\n",
      "Epoch: [1][ 300/1282]\tTime  2.264 ( 1.675)\tData  0.003 ( 0.053)\tLoss 3.1766e+00 (3.2485e+00)\tAcc@1  33.60 ( 30.99)\tAcc@5  55.40 ( 56.46)\n",
      "Epoch: [1][ 310/1282]\tTime  2.421 ( 1.675)\tData  0.002 ( 0.054)\tLoss 3.1221e+00 (3.2444e+00)\tAcc@1  36.80 ( 31.05)\tAcc@5  60.20 ( 56.56)\n",
      "Epoch: [1][ 320/1282]\tTime  2.794 ( 1.676)\tData  0.002 ( 0.053)\tLoss 3.1300e+00 (3.2415e+00)\tAcc@1  34.00 ( 31.08)\tAcc@5  58.40 ( 56.60)\n",
      "Epoch: [1][ 330/1282]\tTime  2.502 ( 1.675)\tData  0.002 ( 0.051)\tLoss 3.0978e+00 (3.2393e+00)\tAcc@1  36.40 ( 31.13)\tAcc@5  62.00 ( 56.64)\n",
      "Epoch: [1][ 340/1282]\tTime  2.611 ( 1.675)\tData  0.002 ( 0.050)\tLoss 3.1287e+00 (3.2356e+00)\tAcc@1  34.40 ( 31.18)\tAcc@5  58.00 ( 56.70)\n",
      "Epoch: [1][ 350/1282]\tTime  2.737 ( 1.675)\tData  0.002 ( 0.048)\tLoss 3.2075e+00 (3.2321e+00)\tAcc@1  32.00 ( 31.23)\tAcc@5  57.60 ( 56.77)\n",
      "Epoch: [1][ 360/1282]\tTime  2.536 ( 1.674)\tData  0.002 ( 0.047)\tLoss 3.1240e+00 (3.2282e+00)\tAcc@1  31.20 ( 31.27)\tAcc@5  60.00 ( 56.83)\n",
      "Epoch: [1][ 370/1282]\tTime  2.487 ( 1.674)\tData  0.002 ( 0.046)\tLoss 3.1326e+00 (3.2259e+00)\tAcc@1  32.00 ( 31.28)\tAcc@5  57.20 ( 56.86)\n",
      "Epoch: [1][ 380/1282]\tTime  2.636 ( 1.673)\tData  0.002 ( 0.045)\tLoss 2.8880e+00 (3.2226e+00)\tAcc@1  37.20 ( 31.32)\tAcc@5  63.00 ( 56.92)\n",
      "Epoch: [1][ 390/1282]\tTime  2.856 ( 1.673)\tData  0.002 ( 0.044)\tLoss 3.1460e+00 (3.2190e+00)\tAcc@1  32.00 ( 31.39)\tAcc@5  57.20 ( 56.97)\n",
      "Epoch: [1][ 400/1282]\tTime  2.514 ( 1.673)\tData  0.002 ( 0.043)\tLoss 2.9460e+00 (3.2160e+00)\tAcc@1  34.40 ( 31.44)\tAcc@5  60.60 ( 57.04)\n",
      "Epoch: [1][ 410/1282]\tTime  2.718 ( 1.674)\tData  0.002 ( 0.042)\tLoss 2.9519e+00 (3.2144e+00)\tAcc@1  35.00 ( 31.48)\tAcc@5  60.80 ( 57.06)\n",
      "Epoch: [1][ 420/1282]\tTime  2.471 ( 1.674)\tData  0.003 ( 0.041)\tLoss 3.0618e+00 (3.2113e+00)\tAcc@1  30.20 ( 31.53)\tAcc@5  61.60 ( 57.11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][ 430/1282]\tTime  2.579 ( 1.673)\tData  0.002 ( 0.040)\tLoss 3.0770e+00 (3.2083e+00)\tAcc@1  34.40 ( 31.57)\tAcc@5  61.40 ( 57.16)\n",
      "Epoch: [1][ 440/1282]\tTime  2.591 ( 1.673)\tData  0.002 ( 0.039)\tLoss 2.9669e+00 (3.2056e+00)\tAcc@1  34.40 ( 31.61)\tAcc@5  61.60 ( 57.22)\n",
      "Epoch: [1][ 450/1282]\tTime  2.437 ( 1.674)\tData  0.002 ( 0.038)\tLoss 2.9060e+00 (3.2036e+00)\tAcc@1  34.20 ( 31.64)\tAcc@5  60.40 ( 57.24)\n",
      "Epoch: [1][ 460/1282]\tTime  2.657 ( 1.674)\tData  0.002 ( 0.038)\tLoss 3.1396e+00 (3.2007e+00)\tAcc@1  30.80 ( 31.69)\tAcc@5  59.00 ( 57.29)\n",
      "Epoch: [1][ 470/1282]\tTime  2.674 ( 1.675)\tData  0.002 ( 0.037)\tLoss 3.1846e+00 (3.1978e+00)\tAcc@1  30.80 ( 31.72)\tAcc@5  57.40 ( 57.34)\n",
      "Epoch: [1][ 480/1282]\tTime  2.767 ( 1.675)\tData  0.002 ( 0.036)\tLoss 2.9806e+00 (3.1947e+00)\tAcc@1  36.00 ( 31.78)\tAcc@5  59.80 ( 57.40)\n",
      "Epoch: [1][ 490/1282]\tTime  2.575 ( 1.675)\tData  0.003 ( 0.035)\tLoss 3.0998e+00 (3.1925e+00)\tAcc@1  33.80 ( 31.81)\tAcc@5  58.80 ( 57.44)\n",
      "Epoch: [1][ 500/1282]\tTime  2.951 ( 1.676)\tData  0.003 ( 0.035)\tLoss 3.1043e+00 (3.1900e+00)\tAcc@1  34.40 ( 31.87)\tAcc@5  59.60 ( 57.49)\n",
      "Epoch: [1][ 510/1282]\tTime  2.818 ( 1.677)\tData  0.002 ( 0.034)\tLoss 3.1869e+00 (3.1883e+00)\tAcc@1  31.00 ( 31.90)\tAcc@5  58.20 ( 57.53)\n",
      "Epoch: [1][ 520/1282]\tTime  2.662 ( 1.677)\tData  0.002 ( 0.033)\tLoss 3.0819e+00 (3.1851e+00)\tAcc@1  32.80 ( 31.94)\tAcc@5  59.40 ( 57.59)\n",
      "Epoch: [1][ 530/1282]\tTime  2.603 ( 1.677)\tData  0.002 ( 0.033)\tLoss 3.1018e+00 (3.1826e+00)\tAcc@1  33.00 ( 31.97)\tAcc@5  57.80 ( 57.62)\n",
      "Epoch: [1][ 540/1282]\tTime  2.696 ( 1.677)\tData  0.002 ( 0.032)\tLoss 2.8581e+00 (3.1807e+00)\tAcc@1  34.60 ( 32.01)\tAcc@5  62.20 ( 57.64)\n",
      "Epoch: [1][ 550/1282]\tTime  2.521 ( 1.676)\tData  0.002 ( 0.032)\tLoss 2.8900e+00 (3.1783e+00)\tAcc@1  39.20 ( 32.05)\tAcc@5  64.00 ( 57.69)\n",
      "Epoch: [1][ 560/1282]\tTime  2.723 ( 1.678)\tData  0.002 ( 0.031)\tLoss 2.9404e+00 (3.1757e+00)\tAcc@1  35.40 ( 32.09)\tAcc@5  62.00 ( 57.75)\n",
      "Epoch: [1][ 570/1282]\tTime  2.511 ( 1.677)\tData  0.002 ( 0.031)\tLoss 2.9945e+00 (3.1729e+00)\tAcc@1  35.00 ( 32.13)\tAcc@5  61.40 ( 57.79)\n",
      "Epoch: [1][ 580/1282]\tTime  2.598 ( 1.677)\tData  0.003 ( 0.030)\tLoss 3.1908e+00 (3.1702e+00)\tAcc@1  33.40 ( 32.17)\tAcc@5  57.00 ( 57.84)\n",
      "Epoch: [1][ 590/1282]\tTime  2.848 ( 1.677)\tData  0.003 ( 0.030)\tLoss 3.2621e+00 (3.1680e+00)\tAcc@1  32.40 ( 32.21)\tAcc@5  55.20 ( 57.89)\n",
      "Epoch: [1][ 600/1282]\tTime  2.481 ( 1.676)\tData  0.003 ( 0.029)\tLoss 3.2347e+00 (3.1660e+00)\tAcc@1  31.40 ( 32.24)\tAcc@5  55.60 ( 57.91)\n",
      "Epoch: [1][ 610/1282]\tTime  2.710 ( 1.676)\tData  0.003 ( 0.029)\tLoss 3.0421e+00 (3.1629e+00)\tAcc@1  35.60 ( 32.30)\tAcc@5  58.40 ( 57.97)\n",
      "Epoch: [1][ 620/1282]\tTime  2.750 ( 1.676)\tData  0.002 ( 0.028)\tLoss 2.9053e+00 (3.1604e+00)\tAcc@1  37.80 ( 32.33)\tAcc@5  61.80 ( 58.01)\n",
      "Epoch: [1][ 630/1282]\tTime  2.475 ( 1.676)\tData  0.002 ( 0.028)\tLoss 2.9965e+00 (3.1581e+00)\tAcc@1  35.60 ( 32.37)\tAcc@5  61.80 ( 58.05)\n",
      "Epoch: [1][ 640/1282]\tTime  2.678 ( 1.676)\tData  0.002 ( 0.028)\tLoss 3.0966e+00 (3.1558e+00)\tAcc@1  33.60 ( 32.41)\tAcc@5  56.80 ( 58.08)\n",
      "Epoch: [1][ 650/1282]\tTime  2.626 ( 1.676)\tData  0.002 ( 0.027)\tLoss 2.9100e+00 (3.1537e+00)\tAcc@1  34.80 ( 32.44)\tAcc@5  63.20 ( 58.12)\n",
      "Epoch: [1][ 660/1282]\tTime  2.349 ( 1.676)\tData  0.003 ( 0.027)\tLoss 3.0147e+00 (3.1515e+00)\tAcc@1  34.00 ( 32.48)\tAcc@5  60.40 ( 58.17)\n",
      "Epoch: [1][ 670/1282]\tTime  2.816 ( 1.676)\tData  0.003 ( 0.027)\tLoss 3.0517e+00 (3.1489e+00)\tAcc@1  34.80 ( 32.53)\tAcc@5  60.60 ( 58.21)\n",
      "Epoch: [1][ 680/1282]\tTime  2.592 ( 1.676)\tData  0.003 ( 0.026)\tLoss 2.9541e+00 (3.1465e+00)\tAcc@1  37.00 ( 32.57)\tAcc@5  64.40 ( 58.25)\n",
      "Epoch: [1][ 690/1282]\tTime  2.867 ( 1.676)\tData  0.002 ( 0.026)\tLoss 2.9330e+00 (3.1442e+00)\tAcc@1  36.60 ( 32.61)\tAcc@5  60.60 ( 58.31)\n",
      "Epoch: [1][ 700/1282]\tTime  2.420 ( 1.676)\tData  0.002 ( 0.026)\tLoss 3.0042e+00 (3.1418e+00)\tAcc@1  33.80 ( 32.65)\tAcc@5  59.80 ( 58.34)\n",
      "Epoch: [1][ 710/1282]\tTime  2.475 ( 1.675)\tData  0.002 ( 0.025)\tLoss 3.0659e+00 (3.1387e+00)\tAcc@1  31.60 ( 32.70)\tAcc@5  60.20 ( 58.40)\n",
      "Epoch: [1][ 720/1282]\tTime  2.511 ( 1.675)\tData  0.003 ( 0.025)\tLoss 2.9184e+00 (3.1363e+00)\tAcc@1  34.80 ( 32.73)\tAcc@5  61.80 ( 58.45)\n",
      "Epoch: [1][ 730/1282]\tTime  2.658 ( 1.675)\tData  0.002 ( 0.025)\tLoss 2.9163e+00 (3.1335e+00)\tAcc@1  35.20 ( 32.77)\tAcc@5  63.20 ( 58.50)\n",
      "Epoch: [1][ 740/1282]\tTime  2.918 ( 1.675)\tData  0.003 ( 0.024)\tLoss 3.0503e+00 (3.1313e+00)\tAcc@1  34.40 ( 32.81)\tAcc@5  60.40 ( 58.53)\n",
      "Epoch: [1][ 750/1282]\tTime  2.537 ( 1.676)\tData  0.003 ( 0.024)\tLoss 2.9764e+00 (3.1288e+00)\tAcc@1  34.40 ( 32.86)\tAcc@5  60.20 ( 58.58)\n",
      "Epoch: [1][ 760/1282]\tTime  2.689 ( 1.676)\tData  0.003 ( 0.024)\tLoss 3.0750e+00 (3.1256e+00)\tAcc@1  34.60 ( 32.91)\tAcc@5  58.60 ( 58.63)\n",
      "Epoch: [1][ 770/1282]\tTime  2.840 ( 1.676)\tData  0.002 ( 0.023)\tLoss 2.7935e+00 (3.1225e+00)\tAcc@1  39.80 ( 32.95)\tAcc@5  63.20 ( 58.69)\n",
      "Epoch: [1][ 780/1282]\tTime  2.697 ( 1.675)\tData  0.002 ( 0.023)\tLoss 2.7364e+00 (3.1196e+00)\tAcc@1  42.20 ( 33.01)\tAcc@5  66.20 ( 58.75)\n",
      "Epoch: [1][ 790/1282]\tTime  2.778 ( 1.675)\tData  0.003 ( 0.023)\tLoss 2.8273e+00 (3.1169e+00)\tAcc@1  36.60 ( 33.05)\tAcc@5  64.40 ( 58.79)\n",
      "Epoch: [1][ 800/1282]\tTime  2.648 ( 1.675)\tData  0.003 ( 0.023)\tLoss 2.8606e+00 (3.1143e+00)\tAcc@1  37.40 ( 33.09)\tAcc@5  63.60 ( 58.84)\n",
      "Epoch: [1][ 810/1282]\tTime  2.624 ( 1.676)\tData  0.002 ( 0.022)\tLoss 2.9015e+00 (3.1116e+00)\tAcc@1  34.40 ( 33.13)\tAcc@5  62.40 ( 58.88)\n",
      "Epoch: [1][ 820/1282]\tTime  2.650 ( 1.675)\tData  0.003 ( 0.022)\tLoss 2.9289e+00 (3.1089e+00)\tAcc@1  35.80 ( 33.17)\tAcc@5  62.00 ( 58.93)\n",
      "Epoch: [1][ 830/1282]\tTime  2.788 ( 1.675)\tData  0.003 ( 0.022)\tLoss 2.9288e+00 (3.1070e+00)\tAcc@1  39.20 ( 33.21)\tAcc@5  63.20 ( 58.96)\n",
      "Epoch: [1][ 840/1282]\tTime  2.671 ( 1.676)\tData  0.002 ( 0.022)\tLoss 2.9609e+00 (3.1046e+00)\tAcc@1  36.60 ( 33.25)\tAcc@5  61.40 ( 59.00)\n",
      "Epoch: [1][ 850/1282]\tTime  2.625 ( 1.675)\tData  0.002 ( 0.021)\tLoss 2.7431e+00 (3.1018e+00)\tAcc@1  41.00 ( 33.31)\tAcc@5  66.40 ( 59.06)\n",
      "Epoch: [1][ 860/1282]\tTime  2.532 ( 1.675)\tData  0.003 ( 0.021)\tLoss 2.9754e+00 (3.0993e+00)\tAcc@1  33.80 ( 33.36)\tAcc@5  62.20 ( 59.10)\n",
      "Epoch: [1][ 870/1282]\tTime  2.660 ( 1.675)\tData  0.003 ( 0.021)\tLoss 2.7761e+00 (3.0965e+00)\tAcc@1  39.40 ( 33.40)\tAcc@5  67.00 ( 59.15)\n",
      "Epoch: [1][ 880/1282]\tTime  3.284 ( 1.675)\tData  0.002 ( 0.021)\tLoss 2.8696e+00 (3.0945e+00)\tAcc@1  38.00 ( 33.42)\tAcc@5  64.40 ( 59.18)\n",
      "Epoch: [1][ 890/1282]\tTime  2.683 ( 1.676)\tData  0.002 ( 0.021)\tLoss 2.9443e+00 (3.0919e+00)\tAcc@1  35.60 ( 33.46)\tAcc@5  60.00 ( 59.23)\n",
      "Epoch: [1][ 900/1282]\tTime  2.806 ( 1.676)\tData  0.003 ( 0.020)\tLoss 2.8574e+00 (3.0896e+00)\tAcc@1  39.00 ( 33.50)\tAcc@5  65.00 ( 59.28)\n",
      "Epoch: [1][ 910/1282]\tTime  2.464 ( 1.676)\tData  0.002 ( 0.020)\tLoss 2.7528e+00 (3.0872e+00)\tAcc@1  40.60 ( 33.54)\tAcc@5  67.60 ( 59.32)\n",
      "Epoch: [1][ 920/1282]\tTime  2.634 ( 1.676)\tData  0.003 ( 0.020)\tLoss 2.8887e+00 (3.0845e+00)\tAcc@1  36.40 ( 33.58)\tAcc@5  60.80 ( 59.37)\n",
      "Epoch: [1][ 930/1282]\tTime  2.769 ( 1.676)\tData  0.003 ( 0.020)\tLoss 2.8925e+00 (3.0823e+00)\tAcc@1  36.40 ( 33.62)\tAcc@5  61.40 ( 59.41)\n",
      "Epoch: [1][ 940/1282]\tTime  2.613 ( 1.675)\tData  0.002 ( 0.020)\tLoss 2.9197e+00 (3.0801e+00)\tAcc@1  36.40 ( 33.65)\tAcc@5  61.00 ( 59.46)\n",
      "Epoch: [1][ 950/1282]\tTime  2.542 ( 1.675)\tData  0.003 ( 0.019)\tLoss 2.8878e+00 (3.0776e+00)\tAcc@1  34.60 ( 33.69)\tAcc@5  61.80 ( 59.51)\n",
      "Epoch: [1][ 960/1282]\tTime  2.648 ( 1.675)\tData  0.002 ( 0.019)\tLoss 2.9306e+00 (3.0752e+00)\tAcc@1  36.00 ( 33.74)\tAcc@5  59.80 ( 59.55)\n",
      "Epoch: [1][ 970/1282]\tTime  2.495 ( 1.675)\tData  0.002 ( 0.019)\tLoss 2.8924e+00 (3.0728e+00)\tAcc@1  34.00 ( 33.78)\tAcc@5  62.00 ( 59.60)\n",
      "Epoch: [1][ 980/1282]\tTime  2.587 ( 1.675)\tData  0.002 ( 0.019)\tLoss 2.8246e+00 (3.0702e+00)\tAcc@1  39.00 ( 33.83)\tAcc@5  64.00 ( 59.64)\n",
      "Epoch: [1][ 990/1282]\tTime  3.048 ( 1.675)\tData  0.002 ( 0.019)\tLoss 2.7851e+00 (3.0674e+00)\tAcc@1  38.00 ( 33.88)\tAcc@5  63.40 ( 59.70)\n",
      "Epoch: [1][1000/1282]\tTime  2.512 ( 1.674)\tData  0.002 ( 0.019)\tLoss 2.9208e+00 (3.0656e+00)\tAcc@1  37.40 ( 33.90)\tAcc@5  61.20 ( 59.73)\n",
      "Epoch: [1][1010/1282]\tTime  2.742 ( 1.674)\tData  0.003 ( 0.018)\tLoss 2.8769e+00 (3.0634e+00)\tAcc@1  35.80 ( 33.93)\tAcc@5  62.20 ( 59.77)\n",
      "Epoch: [1][1020/1282]\tTime  2.478 ( 1.674)\tData  0.003 ( 0.018)\tLoss 2.8871e+00 (3.0617e+00)\tAcc@1  35.80 ( 33.96)\tAcc@5  64.00 ( 59.80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1030/1282]\tTime  2.512 ( 1.675)\tData  0.002 ( 0.018)\tLoss 2.7990e+00 (3.0591e+00)\tAcc@1  39.00 ( 34.01)\tAcc@5  65.00 ( 59.84)\n",
      "Epoch: [1][1040/1282]\tTime  2.765 ( 1.675)\tData  0.002 ( 0.018)\tLoss 2.7864e+00 (3.0570e+00)\tAcc@1  36.00 ( 34.05)\tAcc@5  67.20 ( 59.88)\n",
      "Epoch: [1][1050/1282]\tTime  2.521 ( 1.674)\tData  0.002 ( 0.018)\tLoss 2.7155e+00 (3.0544e+00)\tAcc@1  40.40 ( 34.10)\tAcc@5  67.80 ( 59.93)\n",
      "Epoch: [1][1060/1282]\tTime  2.503 ( 1.674)\tData  0.003 ( 0.018)\tLoss 2.7283e+00 (3.0518e+00)\tAcc@1  39.00 ( 34.13)\tAcc@5  67.60 ( 59.99)\n",
      "Epoch: [1][1070/1282]\tTime  2.816 ( 1.674)\tData  0.002 ( 0.018)\tLoss 2.8005e+00 (3.0500e+00)\tAcc@1  37.80 ( 34.16)\tAcc@5  62.60 ( 60.01)\n",
      "Epoch: [1][1080/1282]\tTime  2.694 ( 1.674)\tData  0.002 ( 0.017)\tLoss 2.7506e+00 (3.0478e+00)\tAcc@1  42.00 ( 34.20)\tAcc@5  64.40 ( 60.05)\n",
      "Epoch: [1][1090/1282]\tTime  2.512 ( 1.673)\tData  0.002 ( 0.017)\tLoss 2.7566e+00 (3.0456e+00)\tAcc@1  38.40 ( 34.24)\tAcc@5  65.00 ( 60.09)\n",
      "Epoch: [1][1100/1282]\tTime  2.546 ( 1.673)\tData  0.002 ( 0.017)\tLoss 2.8414e+00 (3.0434e+00)\tAcc@1  36.20 ( 34.27)\tAcc@5  65.20 ( 60.13)\n",
      "Epoch: [1][1110/1282]\tTime  2.637 ( 1.673)\tData  0.003 ( 0.017)\tLoss 2.7252e+00 (3.0418e+00)\tAcc@1  36.00 ( 34.29)\tAcc@5  66.20 ( 60.16)\n",
      "Epoch: [1][1120/1282]\tTime  2.814 ( 1.673)\tData  0.002 ( 0.017)\tLoss 2.8529e+00 (3.0396e+00)\tAcc@1  34.00 ( 34.32)\tAcc@5  61.00 ( 60.20)\n",
      "Epoch: [1][1130/1282]\tTime  2.680 ( 1.674)\tData  0.002 ( 0.017)\tLoss 2.8477e+00 (3.0378e+00)\tAcc@1  37.60 ( 34.36)\tAcc@5  63.80 ( 60.24)\n",
      "Epoch: [1][1140/1282]\tTime  2.516 ( 1.673)\tData  0.002 ( 0.017)\tLoss 2.5762e+00 (3.0356e+00)\tAcc@1  43.60 ( 34.40)\tAcc@5  68.80 ( 60.27)\n",
      "Epoch: [1][1150/1282]\tTime  2.566 ( 1.673)\tData  0.002 ( 0.016)\tLoss 2.8064e+00 (3.0331e+00)\tAcc@1  39.00 ( 34.44)\tAcc@5  62.60 ( 60.31)\n",
      "Epoch: [1][1160/1282]\tTime  2.795 ( 1.673)\tData  0.002 ( 0.016)\tLoss 2.9946e+00 (3.0313e+00)\tAcc@1  36.80 ( 34.46)\tAcc@5  61.40 ( 60.34)\n",
      "Epoch: [1][1170/1282]\tTime  2.698 ( 1.673)\tData  0.002 ( 0.016)\tLoss 2.9095e+00 (3.0295e+00)\tAcc@1  37.80 ( 34.50)\tAcc@5  61.80 ( 60.37)\n",
      "Epoch: [1][1180/1282]\tTime  2.105 ( 1.673)\tData  0.002 ( 0.017)\tLoss 2.8175e+00 (3.0272e+00)\tAcc@1  37.60 ( 34.54)\tAcc@5  63.40 ( 60.42)\n",
      "Epoch: [1][1190/1282]\tTime  2.030 ( 1.672)\tData  0.002 ( 0.019)\tLoss 2.8928e+00 (3.0250e+00)\tAcc@1  40.20 ( 34.58)\tAcc@5  62.40 ( 60.45)\n",
      "Epoch: [1][1200/1282]\tTime  2.407 ( 1.672)\tData  0.003 ( 0.021)\tLoss 2.8183e+00 (3.0227e+00)\tAcc@1  37.60 ( 34.62)\tAcc@5  64.60 ( 60.49)\n",
      "Epoch: [1][1210/1282]\tTime  2.407 ( 1.672)\tData  0.002 ( 0.022)\tLoss 2.9153e+00 (3.0200e+00)\tAcc@1  35.00 ( 34.66)\tAcc@5  63.60 ( 60.54)\n",
      "Epoch: [1][1220/1282]\tTime  2.317 ( 1.672)\tData  0.002 ( 0.022)\tLoss 2.9005e+00 (3.0180e+00)\tAcc@1  37.80 ( 34.71)\tAcc@5  62.20 ( 60.57)\n",
      "Epoch: [1][1230/1282]\tTime  2.380 ( 1.673)\tData  0.002 ( 0.022)\tLoss 2.7364e+00 (3.0156e+00)\tAcc@1  38.80 ( 34.74)\tAcc@5  66.20 ( 60.62)\n",
      "Epoch: [1][1240/1282]\tTime  2.232 ( 1.672)\tData  0.002 ( 0.021)\tLoss 2.7297e+00 (3.0136e+00)\tAcc@1  40.80 ( 34.77)\tAcc@5  66.20 ( 60.65)\n",
      "Epoch: [1][1250/1282]\tTime  2.298 ( 1.672)\tData  0.002 ( 0.021)\tLoss 2.5840e+00 (3.0111e+00)\tAcc@1  41.20 ( 34.81)\tAcc@5  68.20 ( 60.70)\n",
      "Epoch: [1][1260/1282]\tTime  2.242 ( 1.672)\tData  0.002 ( 0.021)\tLoss 2.8281e+00 (3.0089e+00)\tAcc@1  36.40 ( 34.85)\tAcc@5  65.60 ( 60.74)\n",
      "Epoch: [1][1270/1282]\tTime  2.237 ( 1.672)\tData  0.002 ( 0.021)\tLoss 2.7000e+00 (3.0069e+00)\tAcc@1  40.80 ( 34.88)\tAcc@5  64.40 ( 60.78)\n",
      "Epoch: [1][1280/1282]\tTime  2.363 ( 1.672)\tData  0.002 ( 0.021)\tLoss 2.5770e+00 (3.0044e+00)\tAcc@1  41.40 ( 34.93)\tAcc@5  69.00 ( 60.82)\n",
      "Test: [  0/100]\tTime  4.481 ( 4.481)\tLoss 2.2630e+00 (2.2630e+00)\tAcc@1  44.20 ( 44.20)\tAcc@5  76.40 ( 76.40)\n",
      "Test: [ 10/100]\tTime  2.920 ( 1.950)\tLoss 2.3561e+00 (2.8683e+00)\tAcc@1  49.40 ( 37.80)\tAcc@5  72.40 ( 63.98)\n",
      "Test: [ 20/100]\tTime  2.768 ( 1.820)\tLoss 2.6376e+00 (2.8284e+00)\tAcc@1  29.00 ( 35.91)\tAcc@5  68.40 ( 64.20)\n",
      "Test: [ 30/100]\tTime  2.896 ( 1.774)\tLoss 2.5615e+00 (2.7674e+00)\tAcc@1  41.40 ( 35.83)\tAcc@5  67.60 ( 65.27)\n",
      "Test: [ 40/100]\tTime  2.577 ( 1.759)\tLoss 2.7604e+00 (2.7731e+00)\tAcc@1  39.40 ( 36.46)\tAcc@5  66.40 ( 65.25)\n",
      "Test: [ 50/100]\tTime  2.842 ( 1.749)\tLoss 3.8991e+00 (2.9221e+00)\tAcc@1  22.20 ( 34.74)\tAcc@5  42.40 ( 62.52)\n",
      "Test: [ 60/100]\tTime  2.803 ( 1.740)\tLoss 3.4073e+00 (2.9845e+00)\tAcc@1  31.60 ( 34.23)\tAcc@5  54.00 ( 61.42)\n",
      "Test: [ 70/100]\tTime  2.888 ( 1.724)\tLoss 3.5829e+00 (3.0476e+00)\tAcc@1  26.60 ( 33.56)\tAcc@5  52.60 ( 60.39)\n",
      "Test: [ 80/100]\tTime  2.903 ( 1.717)\tLoss 3.1231e+00 (3.0971e+00)\tAcc@1  38.20 ( 33.20)\tAcc@5  57.20 ( 59.49)\n",
      "Test: [ 90/100]\tTime  2.893 ( 1.709)\tLoss 3.4361e+00 (3.1464e+00)\tAcc@1  31.80 ( 32.51)\tAcc@5  53.40 ( 58.62)\n",
      " * Acc@1 33.104 Acc@5 59.296\n",
      "lr: 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, 2):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()[0]))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37dca308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dcf4bb99f4bea973\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dcf4bb99f4bea973\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4bd11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
